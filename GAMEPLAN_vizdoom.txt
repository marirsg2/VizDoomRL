
==================================

For SML paper analysis

1) Vary Epsilon, and exploration time AGAINST the number of actions (8 vs 3) and see how long the optimal policy takes




==================================

IT maybe better to just batch train the lstm. store as episodes.
    seems like you need time distributed module
    review if the look_Back parameter is needed.


Do the lstm save state anywhere else you do predict before fit.
Double check the reset state cases